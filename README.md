This repository 

Demonstrates using BERT from the Hugging Face Transformers library to generate contextual embeddings for words based on their surrounding context. 
Unlike traditional embeddings (eg FastText, Word2Vec) that assign a fixed vector to each word, BERT generates different vectors for the same word depending on how it is used in a sentence.

Example of use

We compare how BERT treats the word "bank" in two different contexts:

“I went to the bank to deposit money." (financial institution)

“We had a picnic by the river." (river side)
